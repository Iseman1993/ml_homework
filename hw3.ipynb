{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T09:59:39.410602Z",
     "start_time": "2021-05-11T09:59:38.246779Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import everygrams\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import random\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Реализуйте базовый частотный метод по Шерлоку Холмсу\n",
    "\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:10.841663Z",
     "start_time": "2021-05-11T10:22:10.831663Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "abc = 'абвгдежзийклмнопрстуфхцчшщъыьэюя '\n",
    "\n",
    "def tokenize(text, tokenizer=tokenizer):\n",
    "    text = ''.join([c for c in text if c.lower() in abc])\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "\n",
    "def get_freqs(text, min_freq=0, n_gram=1):\n",
    "    freqs = dict()\n",
    "    if n_gram > 1:\n",
    "        text = [''.join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "    for key, value in Counter(text).items():\n",
    "        if value/len(text) > min_freq:\n",
    "            freqs[key] = value/len(text)\n",
    "    return freqs\n",
    "\n",
    "\n",
    "def generate_mapping(freqs):\n",
    "    original = list(freqs.keys())\n",
    "    replacements = np.random.choice(original, replace=False, size=len(freqs))\n",
    "    mapping = dict()\n",
    "    for original_char, replacement_char in zip(original, replacements):\n",
    "        mapping[original_char] = replacement_char\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def apply_mapping(text, mapping):\n",
    "    return ''.join([mapping.get(c, 'ь') for c in text])\n",
    "\n",
    "# Здесь мы находим ближайший по частотности символ.\n",
    "# Пробовал использовать просто ранги, но качество хуже.\n",
    "def get_reverse_mapping(corpus_freqs, text_freqs):\n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    reverse_mapping = dict()\n",
    "    for text_char, text_freq in text_freqs_sorted:\n",
    "        min_diff = 1\n",
    "        best_char = None\n",
    "        for corpus_char, corpus_freq in corpus_freqs_sorted:\n",
    "            diff = abs(corpus_freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_char = corpus_char\n",
    "                min_diff = diff\n",
    "\n",
    "        reverse_mapping[text_char] = best_char\n",
    "        corpus_freqs_sorted = [(char, freq) for char, freq in corpus_freqs_sorted if char !=best_char]\n",
    "        \n",
    "    return reverse_mapping\n",
    "\n",
    "\n",
    "def char_accuracy(text1, text2):\n",
    "    assert len(text1) == len(text2)\n",
    "    right_chars = 0\n",
    "    for c1, c2 in zip(text1, text2):\n",
    "        right_chars += int(c1 == c2)\n",
    "    return right_chars / len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:12.393727Z",
     "start_time": "2021-05-11T10:22:12.040665Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "with open('AnnaKarenina.txt' ,'r') as file:\n",
    "    corpus1 = file.readlines()\n",
    "    \n",
    "with open('WarAndPeace.txt' ,'r') as file:\n",
    "    corpus2 = file.readlines()\n",
    "    \n",
    "corpus = corpus1 + corpus2\n",
    "\n",
    "tokenized_corpus = tokenize(' '.join(corpus))\n",
    "corpus_freqs = get_freqs(tokenized_corpus, n_gram=1)\n",
    "mapping = generate_mapping(corpus_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:43.869633Z",
     "start_time": "2021-05-11T10:22:43.863622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в течение многих часов шерлок холмс сидел согнувшись над стеклянной пробиркой в которой варилось чтото на редкость вонючее голова его была опущена на грудь и он казался мне похожим на странную товцую птицу с тусклыми серыми перьями и черным хохолком итак уотсон сказал он внезапно вы не собираетесь вкладывать свои сбережения в южноафриканские ценные бумаги я вздрогнул от удивления как ни привык я к необычайным способностям холмса это внезапное вторжение в самые тайные мои мысли было совершенно необъяснимым как черт возьми вы об этом узнали спросил я он повернулся на стуле держа в руке дымящуюся пробирку и его глубоко сидящие глаза радостно заблистали признайтесь уотсон что вы совершенно сбиты с толку сказал он признаюсь мне следовало бы заставить вас написать об этом на листочке бумаги и подписаться почему потому что через пять минут вы скажете что все это необычайно просто'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('text.txt' ,'r') as file:\n",
    "    text = file.readlines()\n",
    "\n",
    "tokenized_text = tokenize(' '.join(text))\n",
    "encoded_text = apply_mapping(tokenized_text, mapping)\n",
    "text_freqs = get_freqs(encoded_text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:44.324667Z",
     "start_time": "2021-05-11T10:22:44.320677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сьуоромзоьямахзчьрщеасьжовдаыьчадяеьезподьеахмнсжзеиьмщпьеуоыдэммайьгватзвыайьсьыауавайьсщвздаеиьруауаьмщьвопыаеуиьсамлрооьхадасщьохаьт дщьагнбомщьмщьхвнпиьзьамьыщкщдеэьямоьгачашзяьмщьеувщммнльуасънльгузъньеьунеыд язьеов язьговиэязьзьровм яьчачадыаяьзущыьнауеамьеыщкщдьамьсмокщгмаьс ьмоьеатзвщоуоеиьсыдщп сщуиьесазьетовошомзэьсьлшмащфвзыщмеызоьъомм оьтнящхзьэьскпвахмндьауьнпзсдомзэьыщыьмзьгвзс ыьэьыьмоат рщйм яьегаеатмаеуэяьчадяещьюуаьсмокщгмаоьсуавшомзоьсьещя оьущйм оьяазья едзьт даьеасовжоммаьмоатцэемзя яьыщыьровуьсакиязьс ьатьюуаяьнкмщдзьегваездьэьамьгасовмндеэьмщьеундоьповшщьсьвныоьп яэбнлеэьгватзвыньзьохаьхднтаыаьезпэбзоьхдщкщьвщпаеумаькщтдзеущдзьгвзкмщйуоеиьнауеамьруаьс ьеасовжоммаьетзу ьеьуадыньеыщкщдьамьгвзкмщлеиьямоьедопасщдаьт ькщеущсзуиьсщеьмщгзещуиьатьюуаяьмщьдзеуарыоьтнящхзьзьгапгзещуиеэьгарояньгауаяньруаьровокьгэуиьязмнуьс ьеыщшоуоьруаьсеоьюуаьмоат рщймаьгваеуа'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:44.787497Z",
     "start_time": "2021-05-11T10:22:44.783508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'р лиыиеси меойсх ытнор цивкод хокмн нсчик нойеурцснб етч нлидкьееош явогсвдош р доловош ртвсконб ылоло ет вичдонлб роеюыии йокорт ийо гпкт ояущиет ет йвучб с ое дтзткнь меи яохожсм ет нлвтееую лорфую ялсфу н лундкпмс нивпмс яивбьмс с ыивепм хохокдом слтд уолное ндтзтк ое реизтяео рп еи ногсвтилинб рдктчпртлб нрос нгивижиесь р южеотъвсдтендси фиеепи гумтйс ь рзчвойеук ол учсркиесь дтд ес явсрпд ь д еиогпытшепм няоногеонльм хокмнт эло реизтяеои рловжиеси р нтмпи лтшепи мос мпнкс гпко норивциеео еиогаьнесмпм дтд ыивл розбмс рп ог элом узеткс нявонск ь ое яоривеукнь ет нлуки чивжт р вуди чпмьщуюнь явогсвду с ийо йкугодо нсчьщси йктзт втчонлео зтгкснлткс явсзетшлинб уолное ыло рп норивциеео нгслп н локду ндтзтк ое явсзетюнб меи нкичортко гп зтнлтрслб ртн етяснтлб ог элом ет кснлоыди гумтйс с яочяснтлбнь яоыиму яолому ыло ыивиз яьлб мсеул рп ндтжили ыло рни эло еиогпытшео явонло'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping = get_reverse_mapping(corpus_freqs, text_freqs)\n",
    "decoded_text = apply_mapping(encoded_text, reverse_mapping)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:22:49.787753Z",
     "start_time": "2021-05-11T10:22:49.783734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3536723163841808"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(tokenized_text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, так себе разультат :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Базовый частотный метод с биграммами\n",
    "\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:00.030162Z",
     "start_time": "2021-05-11T10:22:59.607270Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_freqs_bigram = get_freqs(tokenized_corpus, n_gram=2)\n",
    "text_freqs_bigram = get_freqs(encoded_text, n_gram=2)\n",
    "\n",
    "corpus_freqs_sorted = sorted(corpus_freqs_bigram.items(), key=lambda x: x[1], reverse=True)\n",
    "text_freqs_sorted = sorted(text_freqs_bigram.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:00.502572Z",
     "start_time": "2021-05-11T10:23:00.495604Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_reverse_mapping_bigram(corpus_freqs, text_freqs, init_mapping=None):\n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if init_mapping is None:\n",
    "        init_mapping = []\n",
    "    reverse_mapping = {k: v for k, v in init_mapping}\n",
    "    \n",
    "    for i, (text_bigram, text_freq) in enumerate(text_freqs_sorted):\n",
    "\n",
    "        filtred_freqs = copy(corpus_freqs_sorted)\n",
    "        \n",
    "        if text_bigram[0] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[0] == reverse_mapping[text_bigram[0]]]\n",
    "            \n",
    "        if text_bigram[1] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[1] == reverse_mapping[text_bigram[1]]]\n",
    "              \n",
    "        min_diff = 1\n",
    "        best_bigram = None\n",
    "        for bigram, freq in filtred_freqs:\n",
    "            diff = abs(freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_bigram = bigram\n",
    "                min_diff = diff\n",
    "                \n",
    "        if text_bigram[0] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[0]] = best_bigram[0]\n",
    "            \n",
    "        if text_bigram[1] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[1]] = best_bigram[1]\n",
    "\n",
    "        \n",
    "    return reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:01.562944Z",
     "start_time": "2021-05-11T10:23:01.558982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в течение многих часов шерлок холмс сидел согнувшись над стеклянной пробиркой в которой варилось чтото на редкость вонючее голова его была опущена на грудь и он казался мне похожим на странную товцую птицу с тусклыми серыми перьями и черным хохолком итак уотсон сказал он внезапно вы не собираетесь вкладывать свои сбережения в южноафриканские ценные бумаги я вздрогнул от удивления как ни привык я к необычайным способностям холмса это внезапное вторжение в самые тайные мои мысли было совершенно необъяснимым как черт возьми вы об этом узнали спросил я он повернулся на стуле держа в руке дымящуюся пробирку и его глубоко сидящие глаза радостно заблистали признайтесь уотсон что вы совершенно сбиты с толку сказал он признаюсь мне следовало бы заставить вас написать об этом на листочке бумаги и подписаться почему потому что через пять минут вы скажете что все это необычайно просто\n",
      "----------------\n",
      "сьуоромзоьямахзчьрщеасьжовдаыьчадяеьезподьеахмнсжзеиьмщпьеуоыдэммайьгватзвыайьсьыауавайьсщвздаеиьруауаьмщьвопыаеуиьсамлрооьхадасщьохаьт дщьагнбомщьмщьхвнпиьзьамьыщкщдеэьямоьгачашзяьмщьеувщммнльуасънльгузъньеьунеыд язьеов язьговиэязьзьровм яьчачадыаяьзущыьнауеамьеыщкщдьамьсмокщгмаьс ьмоьеатзвщоуоеиьсыдщп сщуиьесазьетовошомзэьсьлшмащфвзыщмеызоьъомм оьтнящхзьэьскпвахмндьауьнпзсдомзэьыщыьмзьгвзс ыьэьыьмоат рщйм яьегаеатмаеуэяьчадяещьюуаьсмокщгмаоьсуавшомзоьсьещя оьущйм оьяазья едзьт даьеасовжоммаьмоатцэемзя яьыщыьровуьсакиязьс ьатьюуаяьнкмщдзьегваездьэьамьгасовмндеэьмщьеундоьповшщьсьвныоьп яэбнлеэьгватзвыньзьохаьхднтаыаьезпэбзоьхдщкщьвщпаеумаькщтдзеущдзьгвзкмщйуоеиьнауеамьруаьс ьеасовжоммаьетзу ьеьуадыньеыщкщдьамьгвзкмщлеиьямоьедопасщдаьт ькщеущсзуиьсщеьмщгзещуиьатьюуаяьмщьдзеуарыоьтнящхзьзьгапгзещуиеэьгарояньгауаяньруаьровокьгэуиьязмнуьс ьеыщшоуоьруаьсеоьюуаьмоат рщймаьгваеуа\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text)\n",
    "print('----------------')\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:05.939298Z",
     "start_time": "2021-05-11T10:23:05.886441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " оатвтвттонв гтвово   оитон ков нн о тбтно  гв  ит  овобо аткннвв го о кток го ок а о го оотн   ова а овооотбк  а о  влвттог н  оотг океноо   ятвоовоого б ото воконон нонвто  в итновоо аоовв лоа  х ло атх о оа  кненто тоенто то ннтотовтовенов в нк нотаоко  а  во кононо во втно в о еовто  ктоотат  о кнобе оа о   то ктотитвтно олив опотков кттохтвветок ногтоно нбо гв но ао бт нтвтнококовто от еконоковт кевогвено     кв  аннов нн оога о втно в то а оитвтто о онетоаогветон тоне нтокен о   тоитвв овт кнн втненококовтоао  н нто ео кога но нвонто  о  тноно во   тов н новоо а нтобтоиоо оо ктобення л но о кток ототг огн к к о тбняттогнонооооб  ав онокнт аонто отнвогат  о  а  вова о ео   тоитвв о ктаео оа нк о кононо во отнвол  онвто нтб  он океоно ао та о о ово т оа о кога новоонт а вкток ногтото  б т оа  но  втн о  а н ова овтотно на онтв ао ео коитатова о  тога овт кевогв о о  а \n"
     ]
    }
   ],
   "source": [
    "reverse_mapping_bigram = get_reverse_mapping_bigram(corpus_freqs_bigram, text_freqs_bigram)\n",
    "decoded_text = apply_mapping(encoded_text, reverse_mapping_bigram)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:08.611652Z",
     "start_time": "2021-05-11T10:23:08.607676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04180790960451977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(tokenized_text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало хуже, что неудивительно. Биграмм больше, попасть по частоте в правильные - сложнее. Нужен текст сильно больше.\n",
    "\n",
    "Попробуем добавить 1-2 раскодированных с помощью посимвольного метода символа как инициализацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:14.810163Z",
     "start_time": "2021-05-11T10:23:14.806163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ь', ' '), ('а', 'о')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_mapping = list(reverse_mapping.items())[:2]\n",
    "init_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:39.683511Z",
     "start_time": "2021-05-11T10:23:39.630622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с такапаа ьпоеал косос  алнок лоньс сабан соепрс ася поб стакньппог словалког с котолог соланося ктото по лабкостя сопукаа еоносо аео втно осрнапо по елрбя а оп кононсь ьпа соло аь по стлоппру тосару стаар с трскнтьа салтьа саляььа а калпть лолонкоь аток ротсоп сконон оп спаноспо ст па совалоатася скнобтсотя ссоа свала апаь с у пооплакопскаа ааппта врьоеа ь снблоепрн от рбаснапаь кок па сластк ь к паовткогпть ссосовпостьь лоньсо ето спаноспоа стол апаа с соьта тогпта ьоа ьтсна втно сосал аппо паовшьспаьть кок калт соняьа ст ов етоь рнпона сслосан ь оп сосалпрнсь по стрна бал о с лрка бтььнрусь словалкр а аео енрвоко сабьнаа еноно лобостпо новнастона сланпогтася ротсоп кто ст сосал аппо сватт с тонкр сконон оп сланпоуся ьпа снабосоно вт ностосатя сос посасотя ов етоь по настокка врьоеа а собсасотясь сокаьр сотоьр кто калан сьтя ьапрт ст ско ата кто сса ето паовткогпо слосто'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping_bigram = get_reverse_mapping_bigram(corpus_freqs_bigram, text_freqs_bigram, init_mapping=init_mapping)\n",
    "decoded_text = apply_mapping(encoded_text, reverse_mapping_bigram)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:23:47.194366Z",
     "start_time": "2021-05-11T10:23:47.190373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3898305084745763"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(tokenized_text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики выросли, но прочесть это все так же невозможно :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Метод на основе MCMC-семплирования\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст, разбитый на биграммы - это, по сути, марковская цепь. Частота биграмм - вероятность перехода по цепи.\n",
    "\n",
    "Для обучения перестановки будем считать вероятность порождения именно такого текста как произведение вероятностей всех биграмм, в него входящих. \n",
    "\n",
    "Всего перестановок очень много, поэтому сделаем жадный алгоритм, который использует идею MCMC-семплирования.\n",
    "\n",
    "Алгоритм:\n",
    "\n",
    "0) Инициализируем перестановки, восстанавливаем текст и считаем на нем $p_{current}$ \n",
    "\n",
    "1) Меняем местами пару букв для перестановки\n",
    "\n",
    "2) Восстанавливаем текст с новой перестановкой и считаем на нем $p_{proposal}$  \n",
    "\n",
    "3) Принимаем новую перестановку с \"вероятностью\" $p_{accept} = \\frac{p_{proposal}}{p_{current}}$ \n",
    "\n",
    "4) Возвращаемся к пункту 1\n",
    "\n",
    "Мы можем уйти немного не туда и застрять не в том максимуме, поэтому будем делать много попыток и брать лучшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:24:08.129565Z",
     "start_time": "2021-05-11T10:24:08.119586Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_freqs_smooth(text, min_freq=0, n_gram=2):\n",
    "    freqs = dict()\n",
    "    vocab_len = len(set(text))**n_gram\n",
    "    if n_gram > 1:\n",
    "        text = [''.join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "    for key, value in Counter(text).items():\n",
    "        freqs[key] = (value + 1) / (len(text) + vocab_len) # Сглаживаем, чтобы не было нулей\n",
    "    return freqs\n",
    "\n",
    "def get_text_proba(text, mapping, freqs, n_gram=2):\n",
    "    decoded_text = apply_mapping(text, mapping)\n",
    "    log_proba = 0\n",
    "    for i in range(len(decoded_text) - n_gram):\n",
    "        bigram = decoded_text[i: i + n_gram]\n",
    "        bigram_proba = freqs.get(bigram)\n",
    "        if bigram_proba is None:\n",
    "            bigram_proba = 1 / (len(text) + len(abc)**n_gram) # Сглаживаем, чтобы не было нулей\n",
    "            \n",
    "        log_proba += np.log(bigram_proba)\n",
    "    return log_proba\n",
    "        \n",
    "def get_reverse_mapping_mcmc(encoded_text, abc_encoded, abc_corpus, freqs_corpus, n_iters=10000, n_trials=10, n_gram=2):\n",
    "\n",
    "    accept_count = 0\n",
    "    best_mapping = None\n",
    "    all_mappings = []\n",
    "    best_log_likekihood = -np.inf\n",
    "\n",
    "    for trial in tqdm(range(n_trials), leave=False, position=0, total=n_trials):\n",
    "\n",
    "        abc_encoded = list(abc_encoded)\n",
    "        abc_iter = list(abc_corpus)\n",
    "        reverse_mapping = {k: v for k, v in zip(abc_encoded, abc_iter[:len(abc_encoded)])}\n",
    "        log_proba_current = get_text_proba(encoded_text, reverse_mapping, freqs_corpus, n_gram=n_gram)\n",
    "\n",
    "        for i in range(n_iters):\n",
    "            abc_proposal = abc_iter[:]\n",
    "            idx1, idx2 = np.random.choice(len(abc_proposal), replace=False, size=2)\n",
    "            abc_proposal[idx1], abc_proposal[idx2] = abc_proposal[idx2], abc_proposal[idx1]\n",
    "            reverse_mapping_proposal = {k: v for k, v in zip(abc_encoded, abc_proposal[:len(abc_encoded)])}\n",
    "            log_proba_proposal = get_text_proba(encoded_text, reverse_mapping_proposal, freqs_corpus, n_gram=n_gram)\n",
    "\n",
    "            p_accept = np.exp(log_proba_proposal - log_proba_current)\n",
    "\n",
    "            if p_accept > np.random.rand():\n",
    "                accept_count += 1\n",
    "                abc_iter = abc_proposal\n",
    "                log_proba_current = log_proba_proposal\n",
    "                reverse_mapping = reverse_mapping_proposal\n",
    "\n",
    "        if log_proba_current > best_log_likekihood:\n",
    "            best_log_likekihood = log_proba_current\n",
    "            best_mapping = reverse_mapping\n",
    "            \n",
    "        all_mappings.append(reverse_mapping)\n",
    "\n",
    "\n",
    "    print(f'Best likelihood: {best_log_likekihood}')        \n",
    "    print(f'Accept raito: {accept_count / (n_iters * n_trials)}')\n",
    "    return best_mapping, all_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:24:10.049447Z",
     "start_time": "2021-05-11T10:24:09.573547Z"
    }
   },
   "outputs": [],
   "source": [
    "freqs_corpus = get_freqs_smooth(tokenized_corpus, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:25:57.291835Z",
     "start_time": "2021-05-11T10:24:10.878032Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -4985.946706030881\n",
      "Accept raito: 0.01208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc, \n",
    "    abc_corpus=abc,\n",
    "    freqs_corpus=freqs_corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:26:00.136785Z",
     "start_time": "2021-05-11T10:26:00.132766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в течение многих часов шерлок холмс сидел согнувшись над стеклянной пробиркой в которой варилось чтото на редкость вонючее голова его была опуъена на грудь и он казался мне похожим на странную товцую птицу с тусклыми серыми перьями и черным хохолком итак уотсон сказал он внезапно вы не собираетесь вкладывать свои сбережения в южноафриканские ценные бумаги я вздрогнул от удивления как ни привык я к необычайным способностям холмса это внезапное вторжение в самые тайные мои мысли было совершенно необщяснимым как черт возьми вы об этом узнали спросил я он повернулся на стуле держа в руке дымяъуюся пробирку и его глубоко сидяъие глаза радостно заблистали признайтесь уотсон что вы совершенно сбиты с толку сказал он признаюсь мне следовало бы заставить вас написать об этом на листочке бумаги и подписаться почему потому что через пять минут вы скажете что все это необычайно просто'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(encoded_text, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Расшифруйте сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:35:04.575912Z",
     "start_time": "2021-05-11T10:35:04.572914Z"
    }
   },
   "outputs": [],
   "source": [
    "message = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:35:04.815564Z",
     "start_time": "2021-05-11T10:35:04.811601Z"
    }
   },
   "outputs": [],
   "source": [
    "message_freqs = get_freqs(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:35:08.394518Z",
     "start_time": "2021-05-11T10:35:08.388536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' оаеинтслвркмдупягьыбзчйжшхюцэщфъ', '↹←⇛↟⇒↝⇴↨⇠⇯↷⇌⇊⇞⇈⇷↤↳↾↙⇙↲↞⇆⇰⇸↘⇏')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "message_freqs_sorted = sorted(message_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "abc_corpus = ''.join([c for c, _ in corpus_freqs_sorted])\n",
    "abc_message = ''.join([c for c, _ in message_freqs_sorted])\n",
    "abc_corpus, abc_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:35:17.111289Z",
     "start_time": "2021-05-11T10:35:16.644082Z"
    }
   },
   "outputs": [],
   "source": [
    "freqs_corpus = get_freqs_smooth(tokenized_corpus, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:37:43.529271Z",
     "start_time": "2021-05-11T10:35:18.116676Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1236.0627385039725\n",
      "Accept raito: 0.04439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    message, \n",
    "    abc_encoded=abc_message, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus,\n",
    "    n_iters=10000,\n",
    "    n_trials=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:37:43.617269Z",
     "start_time": "2021-05-11T10:37:43.612282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешац'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(message, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешац'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(message, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успех :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:23:37.355435Z",
     "start_time": "2021-05-11T11:23:37.351444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_message = \"если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\"\n",
    "encoded_message = apply_mapping(message, best_reverse_mapping)\n",
    "char_accuracy(original_message, encoded_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A что если от биграмм перейти к триграммам\n",
    "\n",
    "Бонус: а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Попробуем раскодировать сообщение из пункта 4 триграммами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:23:39.700694Z",
     "start_time": "2021-05-11T11:23:39.695732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' оаеинтслвркмдупягьыбзчйжшхюцэщфъ', '↹←⇛↟⇒↝⇴↨⇠⇯↷⇌⇊⇞⇈⇷↤↳↾↙⇙↲↞⇆⇰⇸↘⇏')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "message_freqs_sorted = sorted(message_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "abc_corpus = ''.join([c for c, _ in corpus_freqs_sorted])\n",
    "abc_message = ''.join([c for c, _ in message_freqs_sorted])\n",
    "abc_corpus, abc_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:23:41.205004Z",
     "start_time": "2021-05-11T11:23:40.711281Z"
    }
   },
   "outputs": [],
   "source": [
    "freqs_corpus_trigramm = get_freqs_smooth(tokenized_corpus, n_gram=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:24:44.840428Z",
     "start_time": "2021-05-11T11:23:41.307693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1726.0526509971126\n",
      "Accept raito: 0.04171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    message, \n",
    "    abc_encoded=abc_message, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus_trigramm,\n",
    "    n_gram=3,\n",
    "    n_iters=10000,\n",
    "    n_trials=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:24:44.948887Z",
     "start_time": "2021-05-11T11:24:44.944960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаф'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(message, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:24:45.053763Z",
     "start_time": "2021-05-11T11:24:45.048002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956521739130435"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_message = \"если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю\"\n",
    "encoded_message = apply_mapping(message, best_reverse_mapping)\n",
    "char_accuracy(original_message, encoded_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось почти идеально, качество выросло. \n",
    "\n",
    "**2. Попробуем тексты подлиннее, может что-то пойдет не так**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:28:11.206776Z",
     "start_time": "2021-05-11T11:28:11.199795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' оаеинтслвркмдупягьыбзчйжшхюцэщфъ', 'бйзу ъдпгшмеотаысвкьяэлчфжринщюхц')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = generate_mapping(corpus_freqs)\n",
    "encoded_text = apply_mapping(tokenized_text, mapping)\n",
    "text_freqs = get_freqs(encoded_text)\n",
    "\n",
    "corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "abc_corpus = ''.join([c for c, _ in corpus_freqs_sorted])\n",
    "abc_text = ''.join([c for c, _ in text_freqs_sorted])\n",
    "abc_corpus, abc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:24:59.017399Z",
     "start_time": "2021-05-11T11:24:45.276259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -4985.946706030881\n",
      "Accept raito: 0.00742\n",
      "-----\n",
      "гбпукуздубезйлдфбкъ йгбиушмйобфйме б дэумб йлзтгид ьбзъэб пуомвззйчбышйсдшойчбгбойпйшйчбгъшдмй ьбкпйпйбзъбшуэой пьбгйзжкуублймйгъбулйбсамъбйытщузъбзъблштэьбдбйзбоъяъм вбезубыйфйрдебзъб пшъззтжбпйгютжбыпдютб бпт омаедб ушаедбыушьведбдбкушзаебфйфймойебдпъобтйп йзб оъяъмбйзбгзуяъызйбгабзуб йсдшъупу ьбгомъэагъпьб гйдб сушуруздвбгбжрзйъхшдоъз одубюуззаубстеълдбвбгяэшйлзтмбйпбтэдгмуздвбоъобздбышдгаобвбобзуйсакъчзаеб ый йсзй пвебфйме ъбнпйбгзуяъызйубгпйшруздубгб ъеаубпъчзаубейдбеа мдбсамйб йгушиуззйбзуйсцв здеаебоъобкушпбгйяьедбгабйсбнпйебтязъмдб ышй дмбвбйзбыйгушзтм вбзъб птмубэушръбгбштоубэаевщтж вбышйсдшотбдбулйблмтсйойб дэвщдублмъяъбшъэй пзйбяъсмд пъмдбышдязъчпу ьбтйп йзбкпйбгаб йгушиуззйб сдпаб бпймотб оъяъмбйзбышдязъж ьбезуб муэйгъмйбсабяъ пъгдпьбгъ бзъыд ъпьбйсбнпйебзъбмд пйкоубстеълдбдбыйэыд ъпь вбыйкуетбыйпйетбкпйбкушуябывпьбедзтпбгаб оърупубкпйбг убнпйбзуйсакъчзйбышй пй\n",
      "-----\n",
      "в течение многих часов шерлок холмс сидел согнувшись над стеклянной пробиркой в которой варилось чтото на редкость вонючее голова его была опуъена на грудь и он казался мне похожим на странную товцую птицу с тусклыми серыми перьями и черным хохолком итак уотсон сказал он внезапно вы не собираетесь вкладывать свои сбережения в южноафриканские ценные бумаги я вздрогнул от удивления как ни привык я к необычайным способностям холмса это внезапное вторжение в самые тайные мои мысли было совершенно необщяснимым как черт возьми вы об этом узнали спросил я он повернулся на стуле держа в руке дымяъуюся пробирку и его глубоко сидяъие глаза радостно заблистали признайтесь уотсон что вы совершенно сбиты с толку сказал он признаюсь мне следовало бы заставить вас написать об этом на листочке бумаги и подписаться почему потому что через пять минут вы скажете что все это необычайно просто\n",
      "-----\n",
      "0.9954802259887006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc_text, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus,\n",
    "    n_gram=2,\n",
    "    n_iters=10000,\n",
    "    n_trials=5,\n",
    ")\n",
    "print('-----')\n",
    "print(encoded_text)\n",
    "print('-----')\n",
    "decoded_text = apply_mapping(encoded_text, best_reverse_mapping)\n",
    "print(decoded_text)\n",
    "print('-----')\n",
    "print(char_accuracy(tokenized_text, decoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:15.670691Z",
     "start_time": "2021-05-11T11:24:59.120019Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -6857.856111757894\n",
      "Accept raito: 0.00908\n",
      "-----\n",
      "гбпукуздубезйлдфбкъ йгбиушмйобфйме б дэумб йлзтгид ьбзъэб пуомвззйчбышйсдшойчбгбойпйшйчбгъшдмй ьбкпйпйбзъбшуэой пьбгйзжкуублймйгъбулйбсамъбйытщузъбзъблштэьбдбйзбоъяъм вбезубыйфйрдебзъб пшъззтжбпйгютжбыпдютб бпт омаедб ушаедбыушьведбдбкушзаебфйфймойебдпъобтйп йзб оъяъмбйзбгзуяъызйбгабзуб йсдшъупу ьбгомъэагъпьб гйдб сушуруздвбгбжрзйъхшдоъз одубюуззаубстеълдбвбгяэшйлзтмбйпбтэдгмуздвбоъобздбышдгаобвбобзуйсакъчзаеб ый йсзй пвебфйме ъбнпйбгзуяъызйубгпйшруздубгб ъеаубпъчзаубейдбеа мдбсамйб йгушиуззйбзуйсцв здеаебоъобкушпбгйяьедбгабйсбнпйебтязъмдб ышй дмбвбйзбыйгушзтм вбзъб птмубэушръбгбштоубэаевщтж вбышйсдшотбдбулйблмтсйойб дэвщдублмъяъбшъэй пзйбяъсмд пъмдбышдязъчпу ьбтйп йзбкпйбгаб йгушиуззйб сдпаб бпймотб оъяъмбйзбышдязъж ьбезуб муэйгъмйбсабяъ пъгдпьбгъ бзъыд ъпьбйсбнпйебзъбмд пйкоубстеълдбдбыйэыд ъпь вбыйкуетбыйпйетбкпйбкушуябывпьбедзтпбгаб оърупубкпйбг убнпйбзуйсакъчзйбышй пй\n",
      "-----\n",
      "в течение многих часов шерлок холмс сидел согнувшись над стеклянной пробиркой в которой варилось чтото на редкость вонючее голова его была опущена на грудь и он казался мне похожим на странную товъую птиъу с тусклыми серыми перьями и черным хохолком итак уотсон сказал он внезапно вы не собираетесь вкладывать свои сбережения в южноацриканские ъенные бумаги я вздрогнул от удивления как ни привык я к необычайным способностям холмса это внезапное вторжение в самые тайные мои мысли было совершенно необфяснимым как черт возьми вы об этом узнали спросил я он повернулся на стуле держа в руке дымящуюся пробирку и его глубоко сидящие глаза радостно заблистали признайтесь уотсон что вы совершенно сбиты с толку сказал он признаюсь мне следовало бы заставить вас написать об этом на листочке бумаги и подписаться почему потому что через пять минут вы скажете что все это необычайно просто\n",
      "-----\n",
      "0.9943502824858758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc_text, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus_trigramm,\n",
    "    n_gram=3,\n",
    "    n_iters=10000,\n",
    "    n_trials=5,\n",
    ")\n",
    "\n",
    "print('-----')\n",
    "print(encoded_text)\n",
    "print('-----')\n",
    "decoded_text = apply_mapping(encoded_text, best_reverse_mapping)\n",
    "print(decoded_text)\n",
    "print('-----')\n",
    "print(char_accuracy(tokenized_text, decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество практически не изменилось.\n",
    "\n",
    "**3. Попробуем еще одну перестановку, но уже с очень коротким текстом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:15.774918Z",
     "start_time": "2021-05-11T11:25:15.769166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' оаеинтслвркмдупягьыбзчйжшхюцэщфъ', ' ктбъаьсчхюшрифвмзнеяэлдйожг')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text = 'это очень короткий текст чтобы проверить гипотезу что совсем маленькие тексты раскодируются последовательностями из двух букв хуже чем из трех'\n",
    "\n",
    "mapping = generate_mapping(corpus_freqs)\n",
    "encoded_text = apply_mapping(short_text, mapping)\n",
    "text_freqs = get_freqs(encoded_text)\n",
    "\n",
    "corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "abc_corpus = ''.join([c for c, _ in corpus_freqs_sorted])\n",
    "abc_text = ''.join([c for c, _ in text_freqs_sorted])\n",
    "abc_corpus, abc_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Биграммы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:24.718596Z",
     "start_time": "2021-05-11T11:25:15.874786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -786.2069554555712\n",
      "Accept raito: 0.05292\n",
      "-----\n",
      "дкт тюбиш ьтсткьъй кбьак юктяэ фстчбсъкш оъфткбвх юкт атчабр рмзбишьъб кбьакэ смаьтнъсхжкал фтазбнтчмкбзшитаклръ ъв нчхе яхьч ехгб юбр ъв ксбе\n",
      "-----\n",
      "жта акори ванатвею товст ктабы зналонети чезатойя кта салсом мупоривео товсты нусваденяътсь засподалутопирастьме ей длях бявл хяго ком ей тнох\n",
      "-----\n",
      "0.3873239436619718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc_text, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus,\n",
    "    n_gram=2,\n",
    "    n_iters=10000,\n",
    "    n_trials=5,\n",
    ")\n",
    "print('-----')\n",
    "print(encoded_text)\n",
    "print('-----')\n",
    "decoded_text = apply_mapping(encoded_text, best_reverse_mapping)\n",
    "print(decoded_text)\n",
    "print('-----')\n",
    "print(char_accuracy(short_text, decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Триграммы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:35.145988Z",
     "start_time": "2021-05-11T11:25:24.821456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1094.0068699740987\n",
      "Accept raito: 0.0475\n",
      "-----\n",
      "дкт тюбиш ьтсткьъй кбьак юктяэ фстчбсъкш оъфткбвх юкт атчабр рмзбишьъб кбьакэ смаьтнъсхжкал фтазбнтчмкбзшитаклръ ъв нчхе яхьч ехгб юбр ъв ксбе\n",
      "-----\n",
      "это очень короткий текст чтобы проверить хипотезу что совсем маленькие тексты раскогирудтся послеговательностями из гвую букв юуже чем из трею\n",
      "-----\n",
      "0.9436619718309859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc_text, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus_trigramm,\n",
    "    n_gram=3,\n",
    "    n_iters=10000,\n",
    "    n_trials=5,\n",
    ")\n",
    "\n",
    "print('-----')\n",
    "print(encoded_text)\n",
    "print('-----')\n",
    "decoded_text = apply_mapping(encoded_text, best_reverse_mapping)\n",
    "print(decoded_text)\n",
    "print('-----')\n",
    "print(char_accuracy(short_text, decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4-граммы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:35.766360Z",
     "start_time": "2021-05-11T11:25:35.252704Z"
    }
   },
   "outputs": [],
   "source": [
    "freqs_corpus_fourgramm = get_freqs_smooth(tokenized_corpus, n_gram=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:25:46.878769Z",
     "start_time": "2021-05-11T11:25:35.965801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1448.716050748896\n",
      "Accept raito: 0.04956\n",
      "-----\n",
      "дкт тюбиш ьтсткьъй кбьак юктяэ фстчбсъкш оъфткбвх юкт атчабр рмзбишьъб кбьакэ смаьтнъсхжкал фтазбнтчмкбзшитаклръ ъв нчхе яхьч ехгб юбр ъв ксбе\n",
      "-----\n",
      "это очень короткий текст чтобы проверить гипотезу что совсем маленькие тексты раскодируфтся последовательностями из двух букв хуже чем из трех\n",
      "-----\n",
      "0.9929577464788732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc_text, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus_fourgramm,\n",
    "    n_gram=4,\n",
    "    n_iters=10000,\n",
    "    n_trials=5,\n",
    ")\n",
    "\n",
    "print('-----')\n",
    "print(encoded_text)\n",
    "print('-----')\n",
    "decoded_text = apply_mapping(encoded_text, best_reverse_mapping)\n",
    "print(decoded_text)\n",
    "print('-----')\n",
    "print(char_accuracy(short_text, decoded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось просто идеально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдение по n-граммам**\n",
    "\n",
    "Похоже на то, что триграммы дают хороший прирост качества для декодирования коротких текстов. Для длинных текстов в принципе и так все хорошо."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
